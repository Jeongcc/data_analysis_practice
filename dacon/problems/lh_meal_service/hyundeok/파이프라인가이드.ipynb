{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I5xwEiEAYiV2"
   },
   "outputs": [],
   "source": [
    "# AutoML을 이용한 ML 구현\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "# suboptmal problem의 iteration 문제는 무시할 것! (suboptimal의 계산횟수를 한정하여 수렴시키겠다는 얘기)\n",
    "# 궁금하면 max_iter라는 값을 인자로 전달받는 ML 알고리즘을 살펴보세요!\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 필요한 알고리즘을 불러와야 합니다!\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, LogisticRegression\n",
    "# Ridge와 Lasso의 hyperparmeter: alpha\n",
    "# Logistic Regressio의 hyperparameter: penalty와 regularization strength인 C값\n",
    "from sklearn.svm import SVR\n",
    "# SVR의 hyperparameter: epsilon, regularization C, gamma, kernel = 'rbf', 'poly', 'sigmoid'\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "# hidden_layer_sizes = (100,) , (10, 10, ) 정도만 activation = 'relu', 'logistic'까지만, alpha =0.0001, solver = 'lbfgs', 'adam'까지만"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train, X1_test, y1_train, y1_test = train_test_split(중식계 트레이닝 데이터, 중식계 target 값, shuffle=True)\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(석식계 트레이닝 데이터, 석식계 target 값, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('preprocessing', None), ('regressor', LinearRegression())])\n",
    "# 우선 파이프라인 객체를 만들어줍니다. 구상하는 파이프라인은 전처리 -> 모델적합\n",
    "# 아시다시피 파이프라인에 전달해야하는 건 steps인데, steps는 tuple을 list로 모아서 전달해야 합니다.\n",
    "# 'preprocessing'과 'regressor'는 키워드로 제가 임의로 설정한 겁니다.\n",
    "\n",
    "pre_list = [MinMaxScaler(), StandardScaler(), None]\n",
    "# 이거는 그냥 계속 반복해서 쓰는 게 귀찮아서 미리 변수에 저장한 거에요!\n",
    "\n",
    "hyperparam_grid = [\n",
    "    {\"regressor\": [LinearRegression()], 'preprocessing': pre_list},\n",
    "    {\"regressor\": [Ridge()], 'preprocessing': pre_list,\n",
    "     \"regressor__alpha\": [0.0001, 0.001, 0.01, 0.1, 1]},\n",
    "    {\"regressor\": [Lasso()], 'preprocessing': pre_list,\n",
    "    \"regressor__alpha\": [0.0001, 0.001, 0.01, 0.1, 1]},\n",
    "    {\"regressor\": [SVR()], 'preprocessing': pre_list,\n",
    "    \"regressor__epsilon\": [0.001, 0.01, 0.1, 1],\n",
    "    \"regressor__C\": [0.0001, 0.001, 0.01, 0.1, 1],\n",
    "    \"regressor__gamma\": [0.0001, 0.001, 0.01, 0.1, 1]},\n",
    "    {\"regressor\": [MLPRegressor()], 'preprocessing': pre_list,\n",
    "    \"regressor__hidden_layer_sizes\": [(100,) , (10, 10, )],\n",
    "    \"regressor__activation\": [\"relu\", \"logistic\"],\n",
    "    \"regressor__solver\": [\"lbfgs\", \"adam\"],\n",
    "    \"regressor__alpha\": [0.0001, 0.001, 0.01, 0.1, 1]}\n",
    "\n",
    "]\n",
    "# grid는 딕셔너리를 list의 형태로 전달하고 있습니다.\n",
    "# 각 알고리즘별 하이퍼파라미터를 '__'로 접근하고 있고 반드시 pipe에 써준 keyword랑 조합해서 써줘야 합니다.\n",
    "\n",
    "\n",
    "# cross-validation을 세부 설정하려고 따로 빼서 선언했습니다.\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "\n",
    "# 중식계를 위해 grid1을, 석식계를 위해 grid1을 만들었습니다.\n",
    "# 왜 scoring이 neg_mean_absolute_error 일까요? Ans: 음수 붙이면 커질수록 성능이 좋아지니까.\n",
    "grid1 = GridSearchCV(pipe, hyperparam_grid, scoring=\"neg_mean_absolute_error\",\n",
    "                   refit=True, cv=kfold)\n",
    "grid2 = GridSearchCV(pipe, hyperparam_grid, scoring=\"neg_mean_absolute_error\",\n",
    "                   refit=True, cv=kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid1.fit(X1_train, y1_train)\n",
    "print(grid1.best_estimator_)\n",
    "print(grid1.best_params_)\n",
    "print(grid1.best_score_)\n",
    "print(grid1.score(X1_test, y1_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid2.fit(X2_train, y2_train)\n",
    "print(grid2.best_estimator_)\n",
    "print(grid2.best_params_)\n",
    "print(grid2.best_score_)\n",
    "print(grid2.score(X2_test, y2_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame(grid1.best_estimator_.predict(test[lfeature_column]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = pd.DataFrame(grid1.best_estimator_.predict(test[dfeature_column]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save = pd.read_csv(\"sample_submission.csv\")\n",
    "save[\"중식계\"] = a\n",
    "save[\"석식계\"] = b\n",
    "save.columns = [\"일자\", \"중식계\", \"석식계\"]\n",
    "save.to_csv(\"submit.csv\", encoding=\"CP949\", index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Untitled2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
